{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Install required pacages\n"
      ],
      "metadata": {
        "id": "NsHUymGz8heI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install open-deep-research\n",
        "!pip install -U langgraph langchain-openai\n",
        "!pip install langgraph-supervisor\n",
        "!pip install pypdf\n",
        "!pip install lancedb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THmMrnQXY_oN",
        "outputId": "dfe04ac5-3e65-45f6-e20b-c2d25a221ae5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting open-deep-research\n",
            "  Downloading open_deep_research-0.0.5-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting langgraph>=0.2.55 (from open-deep-research)\n",
            "  Downloading langgraph-0.2.74-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting langchain-community>=0.3.9 (from open-deep-research)\n",
            "  Downloading langchain_community-0.3.18-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting langchain-openai>=0.3.5 (from open-deep-research)\n",
            "  Downloading langchain_openai-0.3.7-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langchain-anthropic>=0.3.3 (from open-deep-research)\n",
            "  Downloading langchain_anthropic-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: openai>=1.61.0 in /usr/local/lib/python3.11/dist-packages (from open-deep-research) (1.61.1)\n",
            "Collecting tavily-python>=0.5.0 (from open-deep-research)\n",
            "  Downloading tavily_python-0.5.1-py3-none-any.whl.metadata (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.0/91.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-groq>=0.2.4 (from open-deep-research)\n",
            "  Downloading langchain_groq-0.2.4-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting anthropic<1,>=0.47.0 (from langchain-anthropic>=0.3.3->open-deep-research)\n",
            "  Downloading anthropic-0.47.1-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting langchain-core<1.0.0,>=0.3.39 (from langchain-anthropic>=0.3.3->open-deep-research)\n",
            "  Downloading langchain_core-0.3.39-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain-anthropic>=0.3.3->open-deep-research) (2.10.6)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.19 in /usr/local/lib/python3.11/dist-packages (from langchain-community>=0.3.9->open-deep-research) (0.3.19)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community>=0.3.9->open-deep-research) (2.0.38)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community>=0.3.9->open-deep-research) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community>=0.3.9->open-deep-research) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community>=0.3.9->open-deep-research) (3.11.12)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community>=0.3.9->open-deep-research) (9.0.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community>=0.3.9->open-deep-research)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community>=0.3.9->open-deep-research)\n",
            "  Downloading pydantic_settings-2.8.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community>=0.3.9->open-deep-research) (0.3.8)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community>=0.3.9->open-deep-research)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<2,>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community>=0.3.9->open-deep-research) (1.26.4)\n",
            "Collecting groq<1,>=0.4.1 (from langchain-groq>=0.2.4->open-deep-research)\n",
            "  Downloading groq-0.18.0-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain-openai>=0.3.5->open-deep-research)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.0.10 (from langgraph>=0.2.55->open-deep-research)\n",
            "  Downloading langgraph_checkpoint-2.0.16-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph>=0.2.55->open-deep-research)\n",
            "  Downloading langgraph_sdk-0.1.53-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.61.0->open-deep-research) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.61.0->open-deep-research) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.61.0->open-deep-research) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.61.0->open-deep-research) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.61.0->open-deep-research) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai>=1.61.0->open-deep-research) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai>=1.61.0->open-deep-research) (4.12.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.3.9->open-deep-research) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.3.9->open-deep-research) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.3.9->open-deep-research) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.3.9->open-deep-research) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.3.9->open-deep-research) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.3.9->open-deep-research) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.3.9->open-deep-research) (1.18.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai>=1.61.0->open-deep-research) (3.10)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community>=0.3.9->open-deep-research)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community>=0.3.9->open-deep-research)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai>=1.61.0->open-deep-research) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai>=1.61.0->open-deep-research) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.61.0->open-deep-research) (0.14.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.19->langchain-community>=0.3.9->open-deep-research) (0.3.6)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.39->langchain-anthropic>=0.3.3->open-deep-research) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.39->langchain-anthropic>=0.3.3->open-deep-research) (24.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph>=0.2.55->open-deep-research) (1.1.0)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph>=0.2.55->open-deep-research) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community>=0.3.9->open-deep-research) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community>=0.3.9->open-deep-research) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-anthropic>=0.3.3->open-deep-research) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-anthropic>=0.3.3->open-deep-research) (2.27.2)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community>=0.3.9->open-deep-research)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community>=0.3.9->open-deep-research) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community>=0.3.9->open-deep-research) (2.3.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community>=0.3.9->open-deep-research) (3.1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai>=0.3.5->open-deep-research) (2024.11.6)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.39->langchain-anthropic>=0.3.3->open-deep-research) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community>=0.3.9->open-deep-research)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading open_deep_research-0.0.5-py3-none-any.whl (15 kB)\n",
            "Downloading langchain_anthropic-0.3.8-py3-none-any.whl (23 kB)\n",
            "Downloading langchain_community-0.3.18-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_groq-0.2.4-py3-none-any.whl (14 kB)\n",
            "Downloading langchain_openai-0.3.7-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph-0.2.74-py3-none-any.whl (151 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.4/151.4 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tavily_python-0.5.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading anthropic-0.47.1-py3-none-any.whl (239 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.5/239.5 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading groq-0.18.0-py3-none-any.whl (121 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.9/121.9 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langchain_core-0.3.39-py3-none-any.whl (414 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m414.1/414.1 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.0.16-py3-none-any.whl (38 kB)\n",
            "Downloading langgraph_sdk-0.1.53-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.4/45.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.8.0-py3-none-any.whl (30 kB)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, tiktoken, tavily-python, pydantic-settings, langgraph-sdk, groq, dataclasses-json, anthropic, langchain-core, langgraph-checkpoint, langchain-openai, langchain-groq, langchain-anthropic, langgraph, langchain-community, open-deep-research\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.37\n",
            "    Uninstalling langchain-core-0.3.37:\n",
            "      Successfully uninstalled langchain-core-0.3.37\n",
            "Successfully installed anthropic-0.47.1 dataclasses-json-0.6.7 groq-0.18.0 httpx-sse-0.4.0 langchain-anthropic-0.3.8 langchain-community-0.3.18 langchain-core-0.3.39 langchain-groq-0.2.4 langchain-openai-0.3.7 langgraph-0.2.74 langgraph-checkpoint-2.0.16 langgraph-sdk-0.1.53 marshmallow-3.26.1 mypy-extensions-1.0.0 open-deep-research-0.0.5 pydantic-settings-2.8.0 python-dotenv-1.0.1 tavily-python-0.5.1 tiktoken-0.9.0 typing-inspect-0.9.0\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.11/dist-packages (0.2.74)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.11/dist-packages (0.3.7)\n",
            "Requirement already satisfied: langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.3.39)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.10 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.0.16)\n",
            "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.1.53)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.61.1)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.9.0)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (0.3.8)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (4.12.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.10.6)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph) (1.1.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.15)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain-openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.3.0)\n",
            "Collecting langgraph-supervisor\n",
            "  Downloading langgraph_supervisor-0.0.3-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: langgraph>=0.2.71 in /usr/local/lib/python3.11/dist-packages (from langgraph-supervisor) (0.2.74)\n",
            "Requirement already satisfied: langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43 in /usr/local/lib/python3.11/dist-packages (from langgraph>=0.2.71->langgraph-supervisor) (0.3.39)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.10 in /usr/local/lib/python3.11/dist-packages (from langgraph>=0.2.71->langgraph-supervisor) (2.0.16)\n",
            "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in /usr/local/lib/python3.11/dist-packages (from langgraph>=0.2.71->langgraph-supervisor) (0.1.53)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph>=0.2.71->langgraph-supervisor) (0.3.8)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph>=0.2.71->langgraph-supervisor) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph>=0.2.71->langgraph-supervisor) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph>=0.2.71->langgraph-supervisor) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph>=0.2.71->langgraph-supervisor) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph>=0.2.71->langgraph-supervisor) (4.12.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph>=0.2.71->langgraph-supervisor) (2.10.6)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph>=0.2.71->langgraph-supervisor) (1.1.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph>=0.2.71->langgraph-supervisor) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph>=0.2.71->langgraph-supervisor) (3.10.15)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph>=0.2.71->langgraph-supervisor) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph>=0.2.71->langgraph-supervisor) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph>=0.2.71->langgraph-supervisor) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph>=0.2.71->langgraph-supervisor) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph>=0.2.71->langgraph-supervisor) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph>=0.2.71->langgraph-supervisor) (3.0.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph>=0.2.71->langgraph-supervisor) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph>=0.2.71->langgraph-supervisor) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph>=0.2.71->langgraph-supervisor) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph>=0.2.71->langgraph-supervisor) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph>=0.2.71->langgraph-supervisor) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph>=0.2.71->langgraph-supervisor) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph>=0.2.71->langgraph-supervisor) (2.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph>=0.2.71->langgraph-supervisor) (1.3.1)\n",
            "Downloading langgraph_supervisor-0.0.3-py3-none-any.whl (7.1 kB)\n",
            "Installing collected packages: langgraph-supervisor\n",
            "Successfully installed langgraph-supervisor-0.0.3\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-5.3.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Downloading pypdf-5.3.0-py3-none-any.whl (300 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.7/300.7 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-5.3.0\n",
            "Collecting lancedb\n",
            "  Downloading lancedb-0.19.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting deprecation (from lancedb)\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting pylance==0.23.0 (from lancedb)\n",
            "  Downloading pylance-0.23.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.11/dist-packages (from lancedb) (4.67.1)\n",
            "Requirement already satisfied: pydantic>=1.10 in /usr/local/lib/python3.11/dist-packages (from lancedb) (2.10.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lancedb) (24.2)\n",
            "Collecting overrides>=0.7 (from lancedb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: pyarrow>=14 in /usr/local/lib/python3.11/dist-packages (from pylance==0.23.0->lancedb) (17.0.0)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.11/dist-packages (from pylance==0.23.0->lancedb) (1.26.4)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.10->lancedb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.10->lancedb) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.10->lancedb) (4.12.2)\n",
            "Downloading lancedb-0.19.0-cp39-abi3-manylinux_2_28_x86_64.whl (32.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.3/32.3 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pylance-0.23.0-cp39-abi3-manylinux_2_28_x86_64.whl (38.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Installing collected packages: overrides, deprecation, pylance, lancedb\n",
            "Successfully installed deprecation-2.1.0 lancedb-0.19.0 overrides-7.7.0 pylance-0.23.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Pass your OpenAI API key and Tavily API key for accessing web search results.\n",
        "\n"
      ],
      "metadata": {
        "id": "OkSC9wvy3mHD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-proj\"\n",
        "os.environ[\"TAVILY_API_KEY\"] = 'tvly-'\n"
      ],
      "metadata": {
        "id": "dwn5lf_rTKQM"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are creating a real-world case study on export-import business compliance, following different guidelines that companies must adhere to. This example will incorporate export policy tools, import policy regulations, and basic guidance.  \n",
        "\n",
        "To simplify the process, we are using data from the **DGFT Import-Export Policy** available at [DGFT Website](https://www.dgft.gov.in/CP/?opt=itchs-import-export). You can download the necessary data from the provided link.  \n",
        "\n",
        "Feel free to utilize as many resources as needed to align with the requirements."
      ],
      "metadata": {
        "id": "3BPNV1rTHLMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "\n",
        "# Define folders and their respective files\n",
        "folders_and_files = {\n",
        "    \"export_import_policies/how_to_export\": {\n",
        "        \"HTE_basics.pdf\": \"https://raw.githubusercontent.com/akashAD98/dummy_data/main/Export_import_agent/how_to_export/HTE_basics.pdf\"\n",
        "    },\n",
        "    \"export_import_policies/export_product_policy\": {\n",
        "        \"export_of_organic_chem.pdf\": \"https://raw.githubusercontent.com/akashAD98/dummy_data/main/Export_import_agent/export_policy/export_of_organic_chem.pdf\",\n",
        "        \"export_of_spices_nuts.pdf\": \"https://raw.githubusercontent.com/akashAD98/dummy_data/main/Export_import_agent/export_policy/export_of_spices_nuts.pdf\",\n",
        "        \"export_of_sugar_n_product.pdf\": \"https://raw.githubusercontent.com/akashAD98/dummy_data/main/Export_import_agent/export_policy/export_of_sugar_n_prdcut.pdf\",\n",
        "        \"export_of_veggine_nuts_cashew.pdf\": \"https://raw.githubusercontent.com/akashAD98/dummy_data/main/Export_import_agent/export_policy/export_of_veggine_nuts_cashwe.pdf\"\n",
        "    },\n",
        "    \"export_import_policies/import_product_policy\": {\n",
        "        \"import_of_veggie2.pdf\": \"https://raw.githubusercontent.com/akashAD98/dummy_data/main/Export_import_agent/import_policy/import_of_veggie2.pdf\",\n",
        "        \"vegetable_nuts_import.pdf\": \"https://raw.githubusercontent.com/akashAD98/dummy_data/main/Export_import_agent/import_policy/vegitable_nuts_import.pdf\"\n",
        "    }\n",
        "}\n",
        "\n",
        "# Function to create folder if not exists and download files\n",
        "def download_files():\n",
        "    for folder, files in folders_and_files.items():\n",
        "        os.makedirs(folder, exist_ok=True)  # Create folder if not exists\n",
        "        for file_name, url in files.items():\n",
        "            file_path = os.path.join(folder, file_name)\n",
        "            if not os.path.exists(file_path):  # Avoid redownloading\n",
        "                response = requests.get(url)\n",
        "                if response.status_code == 200:\n",
        "                    with open(file_path, \"wb\") as file:\n",
        "                        file.write(response.content)\n",
        "                    print(f\"Downloaded: {file_name} → {folder}\")\n",
        "                else:\n",
        "                    print(f\"Failed to download: {file_name}\")\n",
        "            else:\n",
        "                print(f\"Already exists: {file_name} → {folder}\")\n",
        "\n",
        "# Run the function\n",
        "download_files()\n",
        "print(\"All files downloaded successfully! ✅\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_hP37msIkOv",
        "outputId": "67492b1e-23f2-4b18-efca-1495af524267"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded: HTE_basics.pdf → export_import_policies/how_to_export\n",
            "Downloaded: export_of_organic_chem.pdf → export_import_policies/export_product_policy\n",
            "Downloaded: export_of_spices_nuts.pdf → export_import_policies/export_product_policy\n",
            "Downloaded: export_of_sugar_n_product.pdf → export_import_policies/export_product_policy\n",
            "Downloaded: export_of_veggine_nuts_cashew.pdf → export_import_policies/export_product_policy\n",
            "Downloaded: import_of_veggie2.pdf → export_import_policies/import_product_policy\n",
            "Downloaded: vegetable_nuts_import.pdf → export_import_policies/import_product_policy\n",
            "All files downloaded successfully! ✅\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
        "from langchain_community.vectorstores import LanceDB\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "from lancedb.rerankers import LinearCombinationReranker\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "class DocumentManager:\n",
        "    def __init__(self, directory_path, table_name, embedding_model=\"text-embedding-ada-002\", reranker_weight=0.3):\n",
        "        self.directory_path = directory_path\n",
        "        self.table_name = table_name\n",
        "        self.embedding_model = embedding_model\n",
        "        self.reranker_weight = reranker_weight\n",
        "        self.embeddings = OpenAIEmbeddings(model=embedding_model)\n",
        "        self.reranker = LinearCombinationReranker(weight=reranker_weight)\n",
        "        self.docsearch = self._initialize_docsearch()\n",
        "        print(f\"Embeddings for {self.table_name} are done. You can now use it.\")\n",
        "\n",
        "    def _initialize_docsearch(self):\n",
        "        loader = PyPDFDirectoryLoader(self.directory_path)\n",
        "        documents = loader.load()\n",
        "        if not documents:\n",
        "            print(f\"No documents found in directory: {self.directory_path}\")\n",
        "            return None\n",
        "        else:\n",
        "            print(f\"Loaded {len(documents)} documents from {self.directory_path}\")\n",
        "\n",
        "        text_splitter = CharacterTextSplitter()\n",
        "        documents = text_splitter.split_documents(documents)\n",
        "        if not documents:\n",
        "            print(f\"Document splitting resulted in an empty list for directory: {self.directory_path}\")\n",
        "            return None\n",
        "\n",
        "        return LanceDB.from_documents(\n",
        "            documents,\n",
        "            self.embeddings,\n",
        "            reranker=self.reranker,\n",
        "            table_name=self.table_name\n",
        "        )\n",
        "\n",
        "    def get_docsearch(self):\n",
        "        if self.docsearch is None:\n",
        "            raise ValueError(f\"Document search initialization failed for table: {self.table_name}\")\n",
        "        return self.docsearch\n",
        "\n",
        "# Initialize DocumentManagers for different tools\n",
        "guide_manager = DocumentManager(directory_path=\"/content/export_import_policies/how_to_export\", table_name=\"guide_export_import\")\n",
        "export_policy_manager = DocumentManager(directory_path=\"/content/export_import_policies/export_product_policy\", table_name=\"export_policy_info\")\n",
        "import_policy_manager = DocumentManager(directory_path=\"/content/export_import_policies/import_product_policy\", table_name=\"import_policy_info\")\n",
        "\n",
        "\n",
        "#tools\n",
        "@tool\n",
        "def guide_on_how_to_export(query: str):\n",
        "    \"\"\"\n",
        "    Use this tool when the query is about general guidance on how to start an export-import business, documentation requirements, or basic procedures.\n",
        "\n",
        "    \"\"\"\n",
        "    docsearch = guide_manager.get_docsearch()\n",
        "    docs = docsearch.similarity_search_with_relevance_scores(query, k=5)\n",
        "    return [{\"text\": doc.page_content, \"score\": score} for doc, score in docs]\n",
        "\n",
        "@tool\n",
        "def export_policy(query: str):\n",
        "    \"\"\"\n",
        "    Use this tool when the query is related to export policies, regulations, or HS codes for specific products\n",
        "    \"\"\"\n",
        "    docsearch = export_policy_manager.get_docsearch()\n",
        "    docs = docsearch.similarity_search_with_relevance_scores(query, k=5)\n",
        "    return [{\"text\": doc.page_content, \"score\": score} for doc, score in docs]\n",
        "\n",
        "@tool\n",
        "def import_policy(query: str):\n",
        "    \"\"\"\n",
        "    Use this tool when the query is about import regulations, restrictions, and HS codes for any product.\n",
        "    \"\"\"\n",
        "    docsearch = import_policy_manager.get_docsearch()\n",
        "    docs = docsearch.similarity_search_with_relevance_scores(query, k=5)\n",
        "    return [{\"text\": doc.page_content, \"score\": score} for doc, score in docs]\n",
        "\n",
        "@tool\n",
        "def news_related_exim(query: str):\n",
        "    \"\"\"\n",
        "    use this tool when  we need to search latest inforamtion from net such as exporting importing countries .news realted export import .\n",
        "    \"\"\"\n",
        "    tool = TavilySearchResults(\n",
        "        max_results=5,\n",
        "        search_depth=\"advanced\",\n",
        "        include_answer=True,\n",
        "        include_raw_content=True,\n",
        "        include_images=True,\n",
        "\n",
        "    )\n",
        "    news = tool.invoke({\"query\": query})\n",
        "    return news"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdAIwNfPhMpa",
        "outputId": "a0f973d6-ba20-4473-b023-b6b320c04e0a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 94 documents from /content/export_import_policies/how_to_export\n",
            "Embeddings for guide_export_import are done. You can now use it.\n",
            "Loaded 138 documents from /content/export_import_policies/export_product_policy\n",
            "Embeddings for export_policy_info are done. You can now use it.\n",
            "Loaded 32 documents from /content/export_import_policies/import_product_policy\n",
            "Embeddings for import_policy_info are done. You can now use it.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Use openai llm . # feel free to use any llm\n",
        "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
        "\n",
        "# List of tools\n",
        "tools = [guide_on_how_to_export, export_policy,import_policy,news_related_exim]\n",
        "\n",
        "system_prompt = \"\"\"You are an expert import export assistant bot. use the avaialble tools for asnwering user quetions. only search the realted prdcut on inofmration if not abibale simply return nithing .try to give best answer to user so he wil get all infromatino\"\"\"\n",
        "\n",
        "memory = MemorySaver()\n",
        "\n",
        "# Create the agent\n",
        "graph = create_react_agent(model, tools=tools,prompt=system_prompt, checkpointer=memory)\n",
        "\n",
        "# Function to print output stream\n",
        "def print_stream(stream):\n",
        "    for s in stream:\n",
        "        message = s[\"messages\"][-1]\n",
        "        if isinstance(message, tuple):\n",
        "            print(message)\n",
        "        else:\n",
        "            message.pretty_print()\n",
        "\n",
        "# Example usage:\n",
        "\n",
        "config = {\"configurable\": {\"thread_id\": \"thread-1\"}}\n",
        "\n",
        "\n",
        "inputs = {\"messages\": [(\"user\", \"i want to export organic chemicals acyclic aldehyde.\")]}\n",
        "print_stream(graph.stream(inputs,config,stream_mode=\"values\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLVgPDjrJd6E",
        "outputId": "b558a2fb-6984-43ae-b283-26217aa62465"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "i want to export organic chemicals acyclic aldehyde.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  export_policy (call_KMWynrWc5UI7w3IJ5s07kSG8)\n",
            " Call ID: call_KMWynrWc5UI7w3IJ5s07kSG8\n",
            "  Args:\n",
            "    query: export policies and regulations for organic chemicals acyclic aldehyde\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: export_policy\n",
            "\n",
            "[{\"text\": \"Product Description and Export Policy\\nItc(hs) Code. Description Export\\nPolicy Policy Condition\\n2901 Acyclic hydrocarbons.\\n29011000 Saturated Free\\n29012100 Unsaturated : -- Ethylene Free\\n29012200 Unsaturated : -- Propene (propylene) Free\\n29012300 Unsaturated : -- Butene (butylene) and isomers thereof Free\\n29012400 Unsaturated : -- Buta-1,3-diene and isoprene Free\\n290129 Unsaturated : -- Other\\n29012910 Acetylene, whether or not in dissolved condition Free\\n29012920 Heptene (Heptylene) Free\\n29012930 Dihydromyrcene Free\\n29012940 Tetradecene Free\\n29012990 Other Free\\n2902 Cyclic hydrocarbons.\\n29021100 Cyclanes, cyclenes and cycloterpenes : -- Cyclohexane Free\\n290219 Cyclanes, cyclenes and cycloterpenes : -- Other\\n29021910 Cyclopropyl actetylene Free\", \"score\": 0.738354766814735}, {\"text\": \"29124991 Other: ---- Aldehyde-alcohols Free\\n29124999 Other Free\\n29125000 Cyclic polymers of aldehydes Free\\n29126000 Paraformaldehyde Free\\n2913 Halogenated, sulphonated, nitrated or nitrosated\\nderivatives of products of heading 29.12.\\n291300 Halogenated, sulphonated, nitrated or nitrosated\\nderivatives of products of heading 2912 :\\n29130010 Ortho-chloro-benzaldehyde Free\\n29130090 Other Free\\n2914\\nKetones and quinones, whether or not with other oxygen\\nfunction, and their halogenated, sulphonated, nitrated or\\nnitrosated derivatives.\\n29141100 Acyclic ketones without other oxygen function : -- Acetone Free\\n29141200 Acyclic ketones without other oxygen function : --\\nButanone (methyl ethyl ketone) Free\\nHowever, Export of\\nMethyl Ethyl Ketone\\nis free subject to No\\nObjection Certificate\\nfrom Narcotics\\nCommissioner of\\nIndia, Gwalior\\n55(RE-2013)/2009-\\n2014\\n03.12.20\\n13\\n29141300 Acyclic ketones without other oxygen function : -- 4-\\nMethylpentan-2-one (methyl isobutyl ketone) Free\\n291419 Acyclic ketones without other oxygen function : -- Other\", \"score\": 0.7216215617986671}, {\"text\": \"Policy Condition\\nSl.No. Notes Notification\\nDate Notification No\\n1 Export of Hydrofluorocarbons (HFCs) is permitted with an Export Authorization subject to NOC\\nof Ozone Cell, MoEF&CC\\n2\\n1. Export of chemicals under Montreal Protocol when exported to a country which is not party to\\nthe Montreal Protocol on substances that Deplete the Ozone Layer is prohibited and not\\npermitted to be exported. 2. However, Export of Chemicals included to the Montreal Protocol on\\nsubstances that deplete the Ozone Layer is Restricted and permitted under a Restricted Export\\nAuthorisation. 3. Restricted or Prohibited as above depending upon whether country is signatory\\nof Montreal protocol or not.\", \"score\": 0.7173119411713069}, {\"text\": \"Certificate from\\nNarcotics\\nCommissioner of\\nIndia, Gwalior\\n293963 Lysergic acid and its salts\\n29396300 Alkaloids of rye ergot and their derivatives; salts thereof : --\\nLysergic acid and its salts Free\\nHowever, Export of\\nLysergic acid and its\\nsalts is Free subject\\nto No Objection\\nCertificate from\\nNarcotics\\nCommissioner of\\nIndia, Gwalior\\n29396900 Alkaloids of rye ergot and their derivatives; salts thereof :--\\nOther Free\\n29397200 Other, of vegetal origin: - - Cocaine, ecgonine; salts, esters\\nand other derivatives thereof Free\\n29397900 Other, of vegetal origin: - - Other Free\\n29398000 Other Free\\n29400000\\nSugars, chemically pure, other than sucrose, lactose,\\nmaltose, glucose and fructose; sugar ethers, sugar acetals\\nand sugar esters, and their salts, other than products of\\nheadings2937, 2938 or 2939\\nFree\\n2941 Antibiotics.\\n294110 Penicillins and their derivatives with a penicillanic acid\\nstructure; salt thereof\\n29411010 Penicillins and its salts ( eg procaine penicillin, penicillin G- Free\", \"score\": 0.710345214626426}, {\"text\": \"29037900 Halogenated derivatives of cyclanic, cyclenic or\\ncycloterpenic hydrocarbons :\\nRestrict\\ned\\nSubject to policy\\ncondition 2 of the\\nchapter.\\n29038100 \\\"1,2,3,4,5,6-Hexachlorocyclohexane (HCH (ISO)),\\nincluding lindane (ISO, INN)\\\" Free\\n29038200 Aldrin (ISO), chlordane (ISO) and heptachlor (ISO) Free\\n29038300 Mirex (ISO) Free\\n29038900 Other Restrict\\ned\\nSubject to policy\\ncondition 2 of the\\nchapter.\\n290391 Halogenated derivatives of aromatic hydrocarbons : --\\nChlorobenzene, o-dichlorobenzene and p-dichlorobenzene\\n29039110 Chlorobenzene (monochloro) Free\\n29039120 o - dichlorobenzene (Orthodichlorobenzene Free\\n29039130 p - dichlorobenzene (Paradichlorobenzene) Free\\n290392\\nHalogenated derivatives of aromatic hydrocarbons : --\\nHexachlorobenzene (ISO) and DDT (ISO) (clofenotane\\n(INN), 1,1,1-trichloro-2,2-bis(p-chlorophenyl)ethane)\\n29039210 Hexachlorobenzene (ISO) Free\\n29039221 DDT (ISO) (clofenotane (INN),1,1,1-trichloro-2,2-bis (p-\\nchlorophenyl)ethane): ---- DDT Technical 75 Wdp Free\\n29039229 DDT (ISO) (clofenotane (INN),1,1,1-trichloro-2,2-bis (p-\\nchlorophenyl)ethane): ---- Other Free\\n29039300 Halogenated derivatives of aromatic hydrocarbons : -- Free\", \"score\": 0.7100588689376428}]\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "The export of organic chemicals, specifically acyclic aldehydes, is generally free from restrictions. Here are some relevant details:\n",
            "\n",
            "- **HS Code**: 29124999 - Other acyclic aldehydes are free for export.\n",
            "- **Policy**: The export policy for acyclic aldehydes is generally free, meaning there are no specific restrictions or conditions applied to their export.\n",
            "\n",
            "However, it's always a good idea to check with local export authorities or a trade consultant to ensure compliance with any specific regulations or documentation requirements that may apply to your particular situation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we can see that its using memory"
      ],
      "metadata": {
        "id": "PWB-hgzx8VQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "config = {\"configurable\": {\"thread_id\": \"thread-1\"}}\n",
        "\n",
        "inputs = {\"messages\": [(\"user\", \"explain me in more simple points.\")]}\n",
        "print_stream(graph.stream(inputs,config,stream_mode=\"values\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXzieoD_hMt6",
        "outputId": "222678b0-cbe4-4b6b-925a-efc718096622"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "explain me in more simple points.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Certainly! Here are the key points for exporting acyclic aldehydes:\n",
            "\n",
            "1. **No Restrictions**: You can export acyclic aldehydes without any special restrictions or conditions.\n",
            "\n",
            "2. **HS Code**: The Harmonized System (HS) code for acyclic aldehydes is 29124999. This code is used for classification in international trade.\n",
            "\n",
            "3. **Documentation**: While there are no specific restrictions, you should still ensure that all standard export documentation is in order, such as invoices, packing lists, and any necessary certificates.\n",
            "\n",
            "4. **Check Local Regulations**: It's always wise to verify with local export authorities or a trade expert to ensure there are no additional requirements specific to your country or the destination country.\n",
            "\n",
            "These points should help you understand the basic requirements for exporting acyclic aldehydes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "670x-CHUhMwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ml-xtvPPhMzf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}